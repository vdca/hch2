splitid <- do.call(rbind.data.frame, splitid)
names(splitid) <- c("chain", "generation")
splitid$chain <- as.integer(as.character(splitid$chain))
splitid$generation <- as.integer(as.character(splitid$generation))
return(splitid)
}
# load(alldatafile)
d <- readRDS("../datuak/hch11/hch11_chains_d_update.rds")
install.packages("keras")
library(keras)
install_keras(tensorflow = "gpu") # GPU version
install_keras(tensorflow = "gpu") # GPU version
install_keras(tensorflow = "gpu") # GPU version
rm(list=ls())
library(tidyverse)
library(tidytext)
library(stringr)
theme_set(theme_bw())
d <- read_lines("https://www.nieuweband.nl/producten/groepen/3/1000/")
d
d <- read_lines("https://www.ekoplaza.nl/search/qry=pindakaas")
d <- read_lines("https://www.ekoplaza.nl/search/qry=pindakaas")
d
d %>%
str_extract("producten")
d %>%
str_extract("producten.*\"")
d %>%
str_extract("producten.*\"") %>%
filter(!is.na(.))
d %>%
str_extract("producten.*\"") %>%
is.na()
d %>%
str_extract("producten.*\"") %>%
.[is.na(.)]
d %>%
str_extract("producten.*\"") %>%
.[!is.na(.)]
d %>%
str_extract("producten.*\"") %>%
str_detect(".jpg")
d %>%
str_extract("producten.*\"") %>%
filter()
d %>%
tbl_df()
d %>%
str_subset("producten.*\"")
?str_subset
d %>%
str_subset("producten.*\"") %>%
str_subset(!"jpg")
d %>%
str_subset("producten.*\"") %>%
!str_subset("jpg")
d %>%
str_subset("producten.*\"") %>%
!str_subset("?!jpg")
d %>%
str_subset("producten.*\"") %>%
str_subset("?!jpg")
d %>%
str_subset("producten.*\"") %>%
.[!str_detect("jpg")]
d %>%
str_subset("producten.*\"") %>%
.[!str_detect(., "jpg")]
d %>%
str_subset("producten/product.*\"") %>%
.[!str_detect(., "jpg")]
d %>%
str_subset("producten/product.*") %>%
.[!str_detect(., "jpg")]
d %>% View
d %>%
str_subset("producten/product.*") %>%
.[!str_detect(., "jpg")]
d %>%
tbl_df()
d %>%
tbl_df() %>%
filter(str_detect(value, "producten/product"))
d %>%
tbl_df() %>% View
d %>%
tbl_df() %>%
filter(str_detect(value, "zout2"))
d %>%
tbl_df() %>%
filter(str_detect(value, "zout2")) %>% pull(value)
d %>%
tbl_df() %>%
filter(str_detect(value, "producten/product"))
d %>%
tbl_df() %>%
filter(str_detect(value, "producten/product")) %>%
filter(str_detect(value, "zout2")) %>% pull(value)
d <- read_lines("https://www.ekoplaza.nl/search/qry=pindakaas")
d %>%
tbl_df() %>%
filter(str_detect(value, "producten/product")) %>%
filter(str_detect(value, "zout2")) %>% pull(value)
d %>%
tbl_df() %>%
filter(str_detect(value, "producten/product"))
d %>%
tbl_df() %>%
filter(str_detect(value, "producten/product")) %>%
mutate(xurl = str_extract(value, "(https.*)"))
d %>%
tbl_df() %>%
filter(str_detect(value, "producten/product")) %>%
mutate(xurl = str_extract(value, "(https.*)")) %>%
select(xurl)
dinfo <- d %>%
tbl_df() %>%
filter(str_detect(value, "producten/product")) %>%
mutate(xurl = str_extract(value, "(https.*)")) %>%
select(xurl) %>%
mutate(info = map_chr(xurl, read_lines))
dinfo <- d %>%
tbl_df() %>%
filter(str_detect(value, "producten/product")) %>%
mutate(xurl = str_extract(value, "(https.*)")) %>%
select(xurl) %>%
mutate(info = map(xurl, read_lines))
View(dinfo)
dinfo$info[1]
get.html.tbl <- function(durl, dn = 1) {
x <- durl %>%
read_html() %>%
html_nodes("table") %>%
html_table(fill = T) %>%
.[[dn]] %>%
repair_names() %>%
tbl_df() %>%
mutate_all(funs(str_replace(., "\\.", ""))) # rm dots in numbers
return(x)
}
get.html.tbl("https://www.ekoplaza.nl/producten/product/pindakaas-fijn-zonder-zout")
?read_html
library(xml2)
get.html.tbl("https://www.ekoplaza.nl/producten/product/pindakaas-fijn-zonder-zout")
library(RCurl)
library(XML)
library(rvest)
get.html.tbl("https://www.ekoplaza.nl/producten/product/pindakaas-fijn-zonder-zout")
dinfo
dinfo %>%
mutate(nutri = map(info, get.html.tbl))
dinfo <- dinfo %>%
mutate(nutri = map(xurl, get.html.tbl))
dinfo %>%
slice(1)
dinfo %>%
slice(1) %>%
mutate(nutri = map(xurl, get.html.tbl))
?mutate_impl
options(error=recover)
dinfo %>%
slice(1) %>%
mutate(nutri = map(xurl, get.html.tbl))
ls()
dots
df
dim(df)
dots
dots_values()
print(i)
?error
?option
options(error=stop)
for (i in dinfo$xurl) {
print(i)
}
for (i in dinfo$xurl) {
print(i)
get.html.tbl(i)
}
dinfo %>%
slice(1) %>%
mutate(nutri = map(xurl, ~ try(get.html.tbl(.x))))
dinfo <- dinfo %>%
mutate(nutri = map(xurl, ~ try(get.html.tbl(.x))))
View(dinfo)
dinfo$xurl
get.html.tbl("https://www.ekoplaza.nl/producten/product/pindakaas8\"")
dinfo <- d %>%
tbl_df() %>%
filter(str_detect(value, "producten/product")) %>%
mutate(xurl = str_extract(value, "(https.*)\"")) %>%
select(xurl)
dinfo
?str_extract
dinfo <- d %>%
tbl_df() %>%
filter(str_detect(value, "producten/product")) %>%
mutate(xurl = str_extract(value, "https.*")) %>%
select(xurl)
dinfo
dinfo <- d %>%
tbl_df() %>%
filter(str_detect(value, "producten/product")) %>%
mutate(xurl = str_extract(value, "https.*"),
xurl = str_replace(xurl, "\"", "")) %>%
select(xurl)
dinfo
dinfo <- dinfo %>%
mutate(nutri = map(xurl, ~ try(get.html.tbl(.x))))
View(dinfo)
dinfo
dinfo %>%
unnest()
dinfo %>%
unnest() %>%
mutate(a = str_extract_all("[0-9]*"))
dinfo %>%
unnest() %>%
mutate(a = str_extract_all(X2, "[0-9]*"))
dinfo %>%
unnest() %>%
mutate(a = str_extract_all(X2, "[0-9]*")) %>%
select(a)
dinfo %>%
unnest() %>%
mutate(a = str_extract_all(X2, "[0-9]*")) %>%
select(a) %>% View
dinfo %>%
unnest() %>%
mutate(a = str_extract_all(X2, "[0-9]*")) %>%
unnest()
dinfo %>%
unnest() %>%
mutate(a = str_extract_all(X2, "[0-9]*")) %>%
unnest() %>%
filter(a != "")
dinfo %>%
unnest() %>%
mutate(a = str_extract_all(X2, "[0-9]*")) %>%
unnest() %>%
filter(a != "",
X1 == "Vet")
dinfo %>%
unnest() %>%
mutate(a = str_extract_all(X2, "[0-9]*")) %>%
unnest() %>%
filter(a != "",
X1 == "Vet")
dinfo %>%
unnest() %>%
mutate(a = str_extract_all(X2, "[0-9]*")) %>%
unnest() %>%
filter(a != "",
X1 == "Vet") %>%
mutate(a = as.numeric(a))
dinfo %>%
unnest() %>%
mutate(a = str_extract_all(X2, "[0-9]*")) %>%
unnest() %>%
filter(a != "",
X1 == "Vet") %>%
mutate(a = as.numeric(a)) %>%
arrange(a)
dinfo %>%
unnest() %>%
mutate(a = str_extract_all(X2, "[0-9]*")) %>%
unnest() %>% View
filter(a != "") %>% View
dinfo %>%
unnest() %>%
mutate(a = str_extract_all(X2, "[0-9]*")) %>%
unnest() %>%
filter(a != "") %>% View
dinfo %>%
unnest() %>%
mutate(a = str_extract_all(X2, "[0-9]*")) %>%
unnest() %>%
filter(a != "") %>%
filter(X1 == "Vet") %>%
mutate(a = as.numeric(a)) %>%
arrange(a)
dinfo %>%
unnest() %>%
mutate(a = str_extract_all(X2, "[0-9]*")) %>%
unnest() %>%
filter(a != "") %>%
filter(X1 == "Vet verzadigd") %>%
mutate(a = as.numeric(a)) %>%
arrange(a)
dinfo %>%
unnest() %>%
mutate(a = str_extract_all(X2, "[0-9]*")) %>%
unnest() %>%
filter(a != "") %>%
filter(X1 == "Eiwit") %>%
mutate(a = as.numeric(a)) %>%
arrange(a)
dinfo %>%
unnest() %>%
mutate(a = str_extract_all(X2, "[0-9]*")) %>%
unnest() %>%
filter(a != "") %>%
filter(X1 == "Energie") %>%
mutate(a = as.numeric(a)) %>%
arrange(a)
View(dinfo)
dinfo %>%
unnest() %>%
mutate(a = str_extract_all(X2, "[0-9]*")) %>%
unnest() %>%
filter(a != "") %>%
filter(X1 == "Energie") %>%
mutate(a = as.numeric(a)) %>%
arrange(-a)
setwd("~/gdrive/aldakor/lana/MCK/gehigarriak/hch2")
rm(list=ls())     # remove previous objects from workspace
source("hch2_funs.R")
library(tidyverse)
theme_set(theme_bw() + theme(strip.background = element_blank()))
library(broom)
library(lme4)
library(lmerTest)
library(stringdist)
d <- readRDS("hch2_sequences.rds") %>% tbl_df() %>%
select(chain, generation, subjID, seqid = seqid1, seqIN = inseq, seqOUT = outseq)
keys <- as.character(1:4)
pgrams <- combis(2, 4, c(keys, "."))
pgrams.subjs <- crossing(d$subjID, pgrams$ngram) %>%
rename(subjID = `d$subjID`, ngram = `pgrams$ngram`)
pgram.f <- d %>%
mutate(seqOUT.boundaries = paste0(".", seqOUT, ".")) %>%
select(subjID, seqOUT.boundaries) %>%
left_join(pgrams.subjs) %>%
filter(str_detect(seqOUT.boundaries, fixed(ngram))) %>%
count(subjID, ngram) %>%
right_join(pgrams.subjs) %>%
left_join(pgrams) %>%
mutate(n = ifelse(is.na(n), as.integer(0), n))
base.prob <- readRDS("hch2_baseprob.rds")
base.prob
pgram.base2 <- base.prob %>%
mutate(n = freq) %>%
select(gramsize, ngram, n)
pgram.base2
pgrams
1,000
pgram.base2
pgram.base2 %>% filter(n != 0)
pgram.base2 %>% filter(n != 0)
pgram.base2 %>% filter(n != 0) %>% select(n)
pgram.base2 %>% filter(n != 0) %>% select(n) %>% min()
minbase2 <- pgram.base2 %>% filter(n != 0) %>% select(n) %>% min() / 1000000
minbase2 <- minbase2*30
minbase2
pgram.f %>%
left_join(pgram.base2, by = c("gramsize", "ngram"))
pgram.rat <- pgram.f %>%
left_join(pgram.base2, by = c("gramsize", "ngram")) %>%   # merge with simulated baseline
mutate(n.subj = n.x) %>%
rename(f.subj = n.x, f.base2 = n.y) %>%
filter(f.base2 != 0 | f.subj != 0) %>%                    # only keep ngrams present in subjects or simulated baseline
left_join(pgram.base1, by = c("gramsize", "ngram", "chain")) %>%  # merge with 'real' baseline, = generation 0
rename(f.base1.smooth = n) %>%
mutate(f.subj.smooth = f.subj) %>%
mutate_each(funs((. + 1) / (max(.) + 1)), c(f.subj.smooth, f.base1.smooth)) %>%    # frequency with Laplace smoothing
mutate_each(funs((. + minbase2) / (max(.) + minbase2)), c(f.base2, f.subj)) %>%    # frequency without smoothing
mutate(logratio1 = log2(f.subj.smooth / f.base1.smooth),
logratio2 = log2(f.subj / f.base2))
pgram.f %>%
left_join(pgram.base2, by = c("gramsize", "ngram")) %>%   # merge with simulated baseline
mutate(n.subj = n.x) %>%
rename(f.subj = n.x, f.base2 = n.y) %>%
filter(f.base2 != 0 | f.subj != 0)
pgram.f
pgram.base1
pgram.f %>%
left_join(pgram.base2, by = c("gramsize", "ngram")) %>%   # merge with simulated baseline
mutate(n.subj = n.x) %>%
rename(f.subj = n.x, f.base2 = n.y) %>%
filter(f.base2 != 0 | f.subj != 0)
pgram.f %>%
left_join(pgram.base2, by = c("gramsize", "ngram")) %>%   # merge with simulated baseline
mutate(n.subj = n.x) %>%
rename(f.subj = n.x, f.base2 = n.y) %>%
filter(f.base2 != 0 | f.subj != 0) %>%                    # only keep ngrams present in subjects or simulated baseline
rename(f.base1.smooth = n)
pgram.f %>%
left_join(pgram.base2, by = c("gramsize", "ngram")) %>%   # merge with simulated baseline
mutate(n.subj = n.x) %>%
rename(f.subj = n.x, f.base2 = n.y) %>%
filter(f.base2 != 0 | f.subj != 0) %>%                    # only keep ngrams present in subjects or simulated baseline
mutate(f.subj.smooth = f.subj)
pgram.f %>%
left_join(pgram.base2, by = c("gramsize", "ngram")) %>%   # merge with simulated baseline
mutate(n.subj = n.x) %>%
rename(f.subj = n.x, f.base2 = n.y) %>%
filter(f.base2 != 0 | f.subj != 0) %>%                    # only keep ngrams present in subjects or simulated baseline
mutate(f.subj.smooth = (f.subj + 1) / (max(f.subj) + 1))
pgram.f %>%
left_join(pgram.base2, by = c("gramsize", "ngram")) %>%   # merge with simulated baseline
mutate(n.subj = n.x) %>%
rename(f.subj = n.x, f.base2 = n.y) %>%
filter(f.base2 != 0 | f.subj != 0) %>%                    # only keep ngrams present in subjects or simulated baseline
mutate(f.subj.smooth = (f.subj + 1) / (max(f.subj) + 1)) %>% # frequency with Laplace smoothing
mutate_each(funs((. + minbase2) / (max(.) + minbase2)), c(f.base2, f.subj)) %>%    # frequency without smoothing
pgram.f %>%
left_join(pgram.base2, by = c("gramsize", "ngram")) %>%   # merge with simulated baseline
mutate(n.subj = n.x) %>%
rename(f.subj = n.x, f.base2 = n.y) %>%
filter(f.base2 != 0 | f.subj != 0) %>%                    # only keep ngrams present in subjects or simulated baseline
mutate(f.subj.smooth = (f.subj + 1) / (max(f.subj) + 1)) %>% # frequency with Laplace smoothing
mutate_each(funs((. + minbase2) / (max(.) + minbase2)), c(f.base2, f.subj))
pgram.f %>%
left_join(pgram.base2, by = c("gramsize", "ngram")) %>% # merge with simulated baseline
mutate(n.subj = n.x) %>%
rename(f.subj = n.x, f.base2 = n.y) %>%
filter(f.base2 != 0 | f.subj != 0) %>% # only keep ngrams present in subjects or simulated baseline
mutate_each(funs((. + minbase2) / (max(.) + minbase2)), c(f.base2, f.subj)) %>% # frequency without smoothing
mutate(logratio2 = log2(f.subj / f.base2))
warnings()
pgram.rat <- pgram.f %>%
left_join(pgram.base2, by = c("gramsize", "ngram")) %>% # merge with simulated baseline
mutate(n.subj = n.x) %>%
rename(f.subj = n.x, f.base2 = n.y) %>%
filter(f.base2 != 0 | f.subj != 0) %>% # only keep ngrams present in subjects or simulated baseline
mutate_each(funs((. + minbase2) / (max(.) + minbase2)), c(f.base2, f.subj)) %>%
mutate(logratio2 = log2(f.subj / f.base2))
?mutate_at
pgram.rat <- pgram.f %>%
left_join(pgram.base2, by = c("gramsize", "ngram")) %>% # merge with simulated baseline
mutate(n.subj = n.x) %>%
rename(f.subj = n.x, f.base2 = n.y) %>%
filter(f.base2 != 0 | f.subj != 0) %>% # only keep ngrams present in subjects or simulated baseline
# mutate_each(funs((. + minbase2) / (max(.) + minbase2)), c(f.base2, f.subj)) %>%
mutate_each(vars(f.base2, f.subj), funs((. + minbase2) / (max(.) + minbase2))) %>%
mutate(logratio2 = log2(f.subj / f.base2))
pgram.rat <- pgram.f %>%
left_join(pgram.base2, by = c("gramsize", "ngram")) %>% # merge with simulated baseline
mutate(n.subj = n.x) %>%
rename(f.subj = n.x, f.base2 = n.y) %>%
filter(f.base2 != 0 | f.subj != 0) %>% # only keep ngrams present in subjects or simulated baseline
# mutate_each(funs((. + minbase2) / (max(.) + minbase2)), c(f.base2, f.subj)) %>%
mutate_at(vars(f.base2, f.subj), funs((. + minbase2) / (max(.) + minbase2))) %>%
mutate(logratio2 = log2(f.subj / f.base2))
pgram.rat
pgram.rat <- pgram.f %>%
left_join(pgram.base2, by = c("gramsize", "ngram")) %>% # merge with simulated baseline
mutate(n.subj = n.x) %>%
rename(f.subj = n.x, f.base2 = n.y) %>%
filter(f.base2 != 0 | f.subj != 0) %>% # only keep ngrams present in subjects or simulated baseline
mutate_at(vars(f.base2, f.subj), funs((. + minbase2) / (max(.) + minbase2))) %>%
mutate(logratio2 = log2(f.subj / f.base2))
stims <- tidy(readRDS("hch2_baseline.rds"))
stims
stims <- stims %>%
rename(sylgram = x) %>%
mutate(id = seq(nrow(stims)))
stims
syllabs <- c("1", "2", "3", "4", ".")
syllabs2 <- c("ban", "bi", "ta", "tin", ".")
onsets <- c("b", "b", "t", "t", ".")
nuclei <- c("a", "i", "a", "i", ".")
codas <- c("n", "-", "-", "n", ".")
basekeymap <- tibble(syllabs, onsets, nuclei, codas, syllabs2)
basekeymap
stims %>%
group_by(id)
stims %>%
group_by(id) %>%
unnest_tokens(syllabs, sylgram, token = str_split, pattern = "")
stims %>%
# group_by(id) %>%
unnest_tokens(syllabs, sylgram, token = str_split, pattern = "")
library(tidytext)
stims %>%
# group_by(id) %>%
unnest_tokens(syllabs, sylgram, token = str_split, pattern = "")
stims %>%
# group_by(id) %>%
unnest_tokens(syllabs, sylgram, token = str_split, pattern = "") %>%
left_join(basekeymap, by = "syllabs")
system.time(
base2 <- stims %>%
# group_by(id) %>%
unnest_tokens(syllabs, sylgram, token = str_split, pattern = "") %>%
left_join(basekeymap, by = "syllabs") %>%
summarise_at(vars(onsets, nuclei, codas), funs(paste(., collapse = "")))
summarise_each(funs(paste(., collapse = "")), onsets, nuclei, codas)
)
base2 <- stims %>%
# group_by(id) %>%
unnest_tokens(syllabs, sylgram, token = str_split, pattern = "") %>%
left_join(basekeymap, by = "syllabs") %>%
summarise_at(vars(onsets, nuclei, codas), funs(paste(., collapse = "")))
base2
View(base2)
stims %>%
slice(1:100) %>%
unnest_tokens(syllabs, sylgram, token = str_split, pattern = "") %>%
left_join(basekeymap, by = "syllabs") %>%
group_by(id) %>%
summarise_at(vars(onsets, nuclei, codas), funs(paste(., collapse = "")))
system.time(
base2 <- stims %>%
unnest_tokens(syllabs, sylgram, token = str_split, pattern = "") %>%
left_join(basekeymap, by = "syllabs") %>%
group_by(id) %>%
summarise_at(vars(onsets, nuclei, codas), funs(paste(., collapse = "")))
)
stims
saveRDS(base2, "hch2_baseline_features.rds")
